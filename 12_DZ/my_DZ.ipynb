{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Задание: Управление проектной структурой и файловой системой\n",
    "**Создание и управление директориями:**\n",
    "- Напишите скрипт, который автоматически создаст следующую структуру директорий для вашего проекта:\n",
    "     ```\n",
    "     project_root/\n",
    "     ├── data/\n",
    "     │   ├── raw/\n",
    "     │   ├── processed/\n",
    "     ├── logs/\n",
    "     ├── backups/\n",
    "     └── output/\n",
    "     ```\n",
    "   - Убедитесь, что все директории созданы, и если они уже существуют, не вызывайте ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Директория уже существует: project_root\\data/raw\n",
      "Директория уже существует: project_root\\data/processed\n",
      "Директория уже существует: project_root\\logs\n",
      "Директория уже существует: project_root\\backups\n",
      "Директория уже существует: project_root\\output\n",
      "Структура проекта успешно создана.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_structure():\n",
    "    # Определяем корневую директорию проекта\n",
    "    project_root = \"project_root\"\n",
    "\n",
    "    # Список директорий, которые нужно создать\n",
    "    directories = [\n",
    "        \"data/raw\",\n",
    "        \"data/processed\",\n",
    "        \"logs\",\n",
    "        \"backups\",\n",
    "        \"output\"\n",
    "    ]\n",
    "# директория списков в цикле, Проходим по списку директорий\n",
    "    for directory in directories:\n",
    "        # Формируем полный путь к директории\n",
    "        full_path = os.path.join(project_root, directory)\n",
    "        \n",
    "        # Проверяем, существует ли уже директория\n",
    "        if not os.path.exists(full_path):\n",
    "            # Если директория не существует, создаем ее\n",
    "            os.makedirs(full_path)\n",
    "            print(f\"Создана директория: {full_path}\")\n",
    "        else:\n",
    "            # Если директория уже существует, выводим сообщение\n",
    "            print(f\"Директория уже существует: {full_path}\")\n",
    "\n",
    "    print(\"Структура проекта успешно создана.\")\n",
    "\n",
    "# Вызываем функцию для создания структуры директорий\n",
    "create_directory_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание и запись данных в файлы:\n",
    "   - В директории `data/raw/` создайте несколько текстовых файлов с произвольным содержимым на разных языках, используя разные кодировки (например, UTF-8, ISO-8859-1).\n",
    "   - Заполните директорию `logs/` лог-файлом с записями о выполнении предыдущих шагов, включая дату и время создания файлов и директорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-17 19:38:07 - Создан файл: project_root\\data\\raw\\file1.txt (кодировка: utf-8)\n",
      "2024-09-17 19:38:07 - Создан файл: project_root\\data\\raw\\file2.txt (кодировка: utf-8)\n",
      "2024-09-17 19:38:07 - Создан файл: project_root\\data\\raw\\file3.txt (кодировка: iso-8859-1)\n",
      "Лог-файл создан: project_root\\logs\\creation_log.txt\n"
     ]
    }
   ],
   "source": [
    "def create_files_and_logs():\n",
    "    # Определяем пути к директориям\n",
    "    raw_data_dir = os.path.join(\"project_root\", \"data\", \"raw\")\n",
    "    logs_dir = os.path.join(\"project_root\", \"logs\")\n",
    "\n",
    "    # Создаем файлы с разным содержимым и кодировками\n",
    "    files_to_create = [\n",
    "        (\"file1.txt\", \"Hello, World!\", \"utf-8\"),\n",
    "        (\"file2.txt\", \"Привет, мир!\", \"utf-8\"),\n",
    "        (\"file3.txt\", \"Bonjour, le monde!\", \"iso-8859-1\"),\n",
    "    ]\n",
    "\n",
    "    log_entries = []\n",
    "\n",
    "    # Создаем файлы и записываем в них данные\n",
    "    for filename, content, encoding in files_to_create:\n",
    "        file_path = os.path.join(raw_data_dir, filename)\n",
    "        with open(file_path, \"w\", encoding=encoding) as file:\n",
    "            file.write(content)\n",
    "        \n",
    "        # Формируем запись для лога\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_entry = f\"{timestamp} - Создан файл: {file_path} (кодировка: {encoding})\"\n",
    "        log_entries.append(log_entry)\n",
    "        print(log_entry)\n",
    "\n",
    "    # Записываем лог-файл\n",
    "    log_file_path = os.path.join(logs_dir, \"creation_log.txt\")\n",
    "    with open(log_file_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(\"\\n\".join(log_entries))\n",
    "\n",
    "    print(f\"Лог-файл создан: {log_file_path}\")\n",
    "\n",
    "# Вызываем функцию для создания файлов и логов\n",
    "create_files_and_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2 чтение, преобразование и сериализация данных\n",
    "1. **Чтение и обработка данных:**\n",
    "   - Напишите скрипт, который будет автоматически читать все файлы из директории `data/raw/`, корректно определяя их кодировки.\n",
    "   - Выполните преобразование данных из каждого файла, заменяя в них все заглавные буквы на строчные и наоборот.\n",
    "   - Сохраните обработанные данные в новые файлы в директорию `data/processed/` с сохранением исходных имен файлов, но добавив к ним суффикс `_processed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in c:\\users\\marina\\new_project\\python_разработчик\\12_кодировки_рериализация данных\\.venv\\lib\\site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработан файл: file1.txt -> file1_processed.txt\n",
      "Обработан файл: file2.txt -> file2_processed.txt\n",
      "Обработан файл: file3.txt -> file3_processed.txt\n",
      "Обработка завершена.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chardet\n",
    "\n",
    "# Функция для определения кодировки файла\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "    return chardet.detect(raw_data)['encoding']\n",
    "\n",
    "# Функция для обработки текста (замена регистра букв)\n",
    "def process_text(text):\n",
    "    return text.swapcase()\n",
    "\n",
    "# Пути к директориям\n",
    "input_dir = r'C:\\Users\\Marina\\new_project\\Python_разработчик\\12_кодировки_рериализация данных\\project_root\\data\\raw'\n",
    "output_dir = r'C:\\Users\\Marina\\new_project\\Python_разработчик\\12_кодировки_рериализация данных\\project_root\\data\\processed'\n",
    "\n",
    "# Создаем выходную директорию, если она не существует\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Обрабатываем каждый файл в input_dir\n",
    "for filename in os.listdir(input_dir):\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    # Определяем кодировку файла\n",
    "    encoding = detect_encoding(input_path)\n",
    "    \n",
    "    # Читаем содержимое файла\n",
    "    with open(input_path, 'r', encoding=encoding) as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Обрабатываем текст\n",
    "    processed_content = process_text(content)\n",
    "    \n",
    "    # Формируем имя выходного файла\n",
    "    output_filename = os.path.splitext(filename)[0] + '_processed' + os.path.splitext(filename)[1]\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # Сохраняем обработанный текст в новый файл\n",
    "    with open(output_path, 'w', encoding=encoding) as file:\n",
    "        file.write(processed_content)\n",
    "    \n",
    "    print(f\"Обработан файл: {filename} -> {output_filename}\")\n",
    "\n",
    "print(\"Обработка завершена.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Сериализация данных:**\n",
    "   - Напишите скрипт для сериализации содержимого всех файлов из директории `data/processed/` в один JSON-файл. \n",
    "   - Включите в этот JSON-файл следующую информацию:\n",
    "     - Имя файла.\n",
    "     - Исходный текст.\n",
    "     - Преобразованный текст.\n",
    "     - Размер файла в байтах.\n",
    "     - Дата последнего изменения файла.\n",
    "   - Сохраните JSON-файл в директорию `output/` с именем `processed_data.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные успешно сериализованы и сохранены в файле: C:\\Users\\Marina\\new_project\\Python_разработчик\\12_кодировки_рериализация данных\\project_root\\output/processed_data.json\n"
     ]
    }
   ],
   "source": [
    "import json                  # Мы импортируем необходимые модуль json для сериализации данных в JSON,\n",
    "from datetime import datetime #  и datetime для работы с датами.\n",
    "\n",
    "# Определяем функцию serialize_files, которая принимает два аргумента:\n",
    "#  путь к входной директории и путь к выходному JSON-файлу.\n",
    "def serialize_files(input_dir, output_file):\n",
    "    result = []  # Внутри функции мы создаем пустой список result, \n",
    "                 # который будет хранить информацию о всех обработанных файлах.\n",
    "    \n",
    "    for filename in os.listdir(input_dir):  # Используем os.listdir() для получения списка всех файлов в указанной директории.\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        if os.path.isfile(file_path):   #Проверяем, является ли он файлом (а не директорией) с помощью os.path.isfile().\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                original_text = f.read()\n",
    "# Открываем файл и читаем его содержимое.\n",
    "#Выполняем простое преобразование текста (в данном случае, перевод в верхний регистр).\n",
    "#Собираем информацию о файле: имя, исходный текст, преобразованный текст, размер и дату последнего изменения.\n",
    "#Добавляем эту информацию в список result.\n",
    "            \n",
    "            transformed_text = original_text.upper()  # Пример преобразования: перевод в верхний регистр\n",
    "            \n",
    "            file_info = {\n",
    "                \"filename\": filename,\n",
    "                \"original_text\": original_text,\n",
    "                \"transformed_text\": transformed_text,\n",
    "                \"size_bytes\": os.path.getsize(file_path),\n",
    "                \"last_modified\": datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat()\n",
    "            }\n",
    "# После обработки всех файлов, открываем выходной JSON-файл и записываем в него собранную информацию с помощью json.dump(). \n",
    "# Используем параметры ensure_ascii=False для корректной записи Unicode-символов и indent=4 для форматирования JSON с отступами.         \n",
    "            result.append(file_info)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Использование функции\n",
    "input_directory = r'C:\\Users\\Marina\\new_project\\Python_разработчик\\12_кодировки_рериализация данных\\project_root\\data\\processed'\n",
    "output_file = r'C:\\Users\\Marina\\new_project\\Python_разработчик\\12_кодировки_рериализация данных\\project_root\\output/processed_data.json'\n",
    "\n",
    "# вызываем функцию serialize_files с указанием путей к входной директории и выходному файлу.\n",
    "serialize_files(input_directory, output_file)\n",
    "\n",
    "print(\"Данные успешно сериализованы и сохранены в файле:\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Задание Работа с резервными копиями и восстановлением данных\n",
    " Создание резервной копии:\n",
    "   - Напишите скрипт, который автоматически создаст архив резервной копии всех файлов из директории `data/` и сохранит его в директорию `backups/` с именем `backup_<дата>.zip`, где `<дата>` — текущая дата в формате `YYYYMMDD`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Резервная копия создана: backups/backup_2024.09.17.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from datetime import datetime\n",
    "# Импортируем необходимые модули: os для работы с файловой системой, \n",
    "# zipfile для создания архивов, и datetime для работы с датами.\n",
    "\n",
    "# Получаем текущую дату в формате YYYYMMDD \n",
    "# с помощью datetime.now().strftime(\"%Y%m%d\").\n",
    "current_date = datetime.now().strftime(\"%Y.%m.%d\")\n",
    "\n",
    "# Задаем имена директорий: source_dir для исходных файлов \n",
    "# и backup_dir для резервных копий.\n",
    "source_dir = \"data/\"\n",
    "backup_dir = \"backups/\"\n",
    "\n",
    "# Создаем имя файла архива, используя текущую дату.\n",
    "backup_filename = f\"backup_{current_date}.zip\"\n",
    "\n",
    "# Формируем полный путь к файлу архива, объединяя директорию для бэкапов и имя файла.\n",
    "backup_path = os.path.join(backup_dir, backup_filename)\n",
    "\n",
    "# Создаем директорию для бэкапов, если она еще не существует, и пользуя os.makedirs()\n",
    "# с параметром exist_ok=True.\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "\n",
    "# Открываем новый ZIP-архив в режиме записи, используя контекстный менеджер with.\n",
    "with zipfile.ZipFile(backup_path, 'w') as zipf:\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "# Используем os.walk() для рекурсивного обхода всех файлов и \n",
    "# поддиректорий в исходной директории.        \n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, source_dir)\n",
    "            zipf.write(file_path, arcname)\n",
    "# Для каждого файла: Получаем полный путь к файлу.\n",
    "# Вычисляем относительный путь файла внутри архива.\n",
    "# Добавляем файл в архив, сохраняя его относительный путь.           \n",
    "\n",
    "print(f\"Резервная копия создана: {backup_path}\") #Выводим сообщение о успешном создании резервной копии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Восстановление данных:\n",
    "   - Напишите скрипт для разархивирования и восстановления данных из созданного архива резервной копии. Убедитесь, что все файлы восстановлены в соответствующие директории, и их содержимое не повреждено."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные восстановлены в директорию: restored_data/\n"
     ]
    }
   ],
   "source": [
    "# Задаем директории: backup_dir для хранения архивов\n",
    "# и restore_dir для восстановленных данных.\n",
    "backup_dir = \"backups/\"\n",
    "restore_dir = \"restored_data/\"\n",
    "\n",
    "# Получаем текущую дату в формате YYYY.MM.DD, \n",
    "# чтобы найти архив, созданный сегодня.\n",
    "current_date = datetime.now().strftime(\"%Y.%m.%d\")\n",
    "\n",
    "# Формируем имя файла архива, используя текущую дату, \n",
    "# и полный путь к архиву.\n",
    "backup_filename = f\"backup_{current_date}.zip\"\n",
    "backup_path = os.path.join(backup_dir, backup_filename)\n",
    "\n",
    "# Создаем директорию для восстановленных данных, используя os.makedirs() \n",
    "# с параметром exist_ok=True, чтобы избежать ошибки, если директория уже существует.\n",
    "os.makedirs(restore_dir, exist_ok=True)\n",
    "\n",
    "# Открываем архив в режиме чтения с помощью zipfile.ZipFile() \n",
    "# и используем метод extractall() для извлечения всех файлов в указанную директорию.\n",
    "with zipfile.ZipFile(backup_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(restore_dir)\n",
    "\n",
    "print(f\"Данные восстановлены в директорию: {restore_dir}\")\n",
    "\n",
    "# Проверка целостности файлов: Используем os.walk() для рекурсивного обхода всех файлов \n",
    "# и поддиректорий в директории с восстановленными данными.\n",
    "# Для каждого файла проверяем его размер с помощью os.path.getsize().\n",
    "# Если размер файла больше 0, считаем его успешно восстановленным.\n",
    "# Если файл пустой, выводим предупреждение о возможном повреждении.\n",
    "for root, dirs, files in os.walk(restore_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            print(f\"Файл {file_path} успешно восстановлен\")\n",
    "        else:\n",
    "            print(f\"Внимание: файл {file_path} пуст или поврежден\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4: Дополнительные задачи с сериализацией и JSON Schema\n",
    "Работа с пользовательскими классами и JSON:**\n",
    "   - Создайте класс `FileInfo`, который будет хранить информацию о файлах, включающую:\n",
    "     - Имя файла.\n",
    "     - Полный путь к файлу.\n",
    "     - Размер файла.\n",
    "     - Дата создания и последнего изменения файла.\n",
    "   - Напишите скрипт, который собирает информацию обо всех файлах в директории `data/processed/` и сериализует их в JSON-файл. Убедитесь, что при десериализации данные восстанавливаются корректно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Сначала создадим класс FileInfo, Класс используется для создания объектов, \n",
    "# которые будут хранить информацию о файлах.\n",
    "class FileInfo:\n",
    "    def __init__(self, name, full_path, size, created_at, modified_at):\n",
    "        self.name = name\n",
    "        self.full_path = full_path # full_path: полный путь к файлу\n",
    "        self.size = size           # size: размер файла\n",
    "        self.created_at = created_at      # created_at: дата и время создания файла\n",
    "        self.modified_at = modified_at    # modified_at: дата и время последнего изменения файла\n",
    "    \n",
    "    # Этот блок кода определяет метод to_dict() в классе FileInfo\n",
    "    # def to_dict(self) - объявление метода\n",
    "    # to_dict(), который принимает только параметр self (ссылку на текущий объект).\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"name\": self.name,     # \"name\": self.name - имя файла\n",
    "            \"full_path\": self.full_path,  # \"full_path\": self.full_path - полный путь к файлу\n",
    "            \"size\": self.size,            # \"size\": self.size - размер файла\n",
    "            \"created_at\": self.created_at.isoformat(), # self.created_at.isoformat() - дата и время создания файла в формате ISO\n",
    "            \"modified_at\": self.modified_at.isoformat() # \"modified_at\": self.modified_at.isoformat()\n",
    "# дата и время последнего изменения файла в формате ISO\n",
    "        }\n",
    "    \n",
    "# @classmethod - это декоратор, который указывает, \n",
    "# что метод from_dict является методом класса, а не методом экземпляра. \n",
    "# def from_dict(cls, data): - объявление метода класса. \n",
    "# Здесь cls - это ссылка на сам класс (а не на экземпляр), data - словарь с данными о файле.\n",
    "# Метод возвращает новый экземпляр класса FileInfo, используя cls() (что эквивалентно FileInfo()), \n",
    "# и передает в конструктор следующие аргументы:   \n",
    "    @classmethod\n",
    "    def from_dict(cls, data):\n",
    "        return cls(\n",
    "            name=data[\"name\"],    # name=full_path=data[\"full_path\"] - полный путь к файлу из словаря\n",
    "            size=data[\"size\"],    # size=data[\"size\"] - размер файла из словаря\n",
    "            created_at=datetime.fromisoformat(data[\"created_at\"]),  # дата создания файла, преобразованная из строки ISO формата в объект datetime \n",
    "            modified_at=datetime.fromisoformat(data[\"modified_at\"]) # Метод datetime.fromisoformat() используется для преобразования строк \n",
    "                                                                    # в формате ISO 8601 обратно в объекты datetime.\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Информация о файлах сохранена в file_info.json\n",
      "Данные успешно десериализованы\n"
     ]
    }
   ],
   "source": [
    "# Функция collect_file_info() собирает информацию о всех файлах в указанной директории.\n",
    "# Мы используем os.listdir() для получения списка файлов и os.stat() для получения информации о каждом файле.\n",
    "# Затем мы сериализуем список объектов FileInfo в JSON-файл, используя метод to_dict().\n",
    "# Для проверки корректности десериализации, мы читаем JSON-файл и восстанавливаем объекты FileInfo с помощью метода from_dict().\n",
    "\n",
    "def collect_file_info(directory):\n",
    "    file_info_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(full_path):\n",
    "            stats = os.stat(full_path)\n",
    "            file_info = FileInfo(\n",
    "                name=filename,\n",
    "                full_path=full_path,\n",
    "                size=stats.st_size,\n",
    "                created_at=datetime.fromtimestamp(stats.st_ctime),\n",
    "                modified_at=datetime.fromtimestamp(stats.st_mtime)\n",
    "            )\n",
    "            file_info_list.append(file_info)\n",
    "    return file_info_list\n",
    "\n",
    "# Сбор информации о файлах\n",
    "directory = \"data/processed/\"\n",
    "file_info_list = collect_file_info(directory)\n",
    "\n",
    "# Сериализация в JSON\n",
    "with open(\"file_info.json\", \"w\") as f:\n",
    "    json.dump([file_info.to_dict() for file_info in file_info_list], f, indent=2)\n",
    "\n",
    "print(\"Информация о файлах сохранена в file_info.json\")\n",
    "\n",
    "# Десериализация из JSON\n",
    "with open(\"file_info.json\", \"r\") as f:\n",
    "    loaded_data = json.load(f)\n",
    "\n",
    "restored_file_info_list = [FileInfo.from_dict(item) for item in loaded_data]\n",
    "\n",
    "print(\"Данные успешно десериализованы\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидация JSON с использованием JSON Schema:**\n",
    "   - Создайте JSON Schema для проверки структуры данных, созданной в предыдущем задании.\n",
    "   - Напишите скрипт, который проверяет валидность JSON-файла, созданного в предыдущем задании, с использованием созданной JSON Schema.\n",
    "   - Обработайте возможные ошибки валидации, предоставив отчет о найденных несоответствиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonschema\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema)\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema)\n",
      "  Downloading rpds_py-0.20.0-cp311-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.20.0-cp311-none-win_amd64.whl (213 kB)\n",
      "Installing collected packages: rpds-py, attrs, referencing, jsonschema-specifications, jsonschema\n",
      "Successfully installed attrs-24.2.0 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 referencing-0.35.1 rpds-py-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Schema создана и сохранена в файл 'person_schema.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "# Здесь мы создаем JSON Schema, которая описывает структуру данных о человеке. \n",
    "# Схема определяет, что объект должен иметь свойства \"name\" (строка), \"age\" \n",
    "# (целое число не меньше 0), \"city\" (строка) и необязательное свойство \"hobbies\" (массив строк).\n",
    "\n",
    "# Определяем JSON Schema\n",
    "schema = {\n",
    "    \"type\": \"object\", # \"type\": \"object\" - указывает, что наша схема описывает объект.\n",
    "    \"properties\": {                    #\"properties\" - определяет свойства объекта:\n",
    "        \"name\": {\"type\": \"string\"},    # \"name\": должно быть строкой\n",
    "        \"age\": {\"type\": \"integer\", \"minimum\": 0},  #\"age\": должно быть целым числом не меньше 0\n",
    "        \"city\": {\"type\": \"string\"},       # \"city\": должно быть строкой\n",
    "        \"hobbies\": {                       # \"hobbies\": должно быть массивом строк\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"}\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\", \"city\"]\n",
    "}\n",
    "# \"required\": [\"name\", \"age\", \"city\"] - указывает, что свойства \"name\", \"age\" и \"city\" обязательны, \n",
    "# а \"hobbies\" - необязательное.\n",
    "\n",
    "# Сохраняем схему в файл\n",
    "with open('person_schema.json', 'w') as schema_file:\n",
    "    json.dump(schema, schema_file, indent=2)\n",
    "\n",
    "print(\"JSON Schema создана и сохранена в файл 'person_schema.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные валидны\n",
      "Ошибка валидации: -5 is less than the minimum of 0\n",
      "\n",
      "Failed validating 'minimum' in schema['properties']['age']:\n",
      "    {'type': 'integer', 'minimum': 0}\n",
      "\n",
      "On instance['age']:\n",
      "    -5\n"
     ]
    }
   ],
   "source": [
    "from jsonschema import validate, ValidationError\n",
    "\n",
    "# Пример корректных данных\n",
    "valid_data = {\n",
    "    \"name\": \"Иван\",\n",
    "    \"age\": 30,\n",
    "    \"city\": \"Москва\",\n",
    "    \"hobbies\": [\"чтение\", \"путешествия\"]\n",
    "}\n",
    "\n",
    "try:\n",
    "    validate(instance=valid_data, schema=schema)\n",
    "    print(\"Данные валидны\")\n",
    "except ValidationError as e:\n",
    "    print(f\"Ошибка валидации: {e}\")\n",
    "\n",
    "# Пример некорректных данных\n",
    "invalid_data = {\n",
    "    \"name\": \"Петр\",\n",
    "    \"age\": -5,  # Отрицательный возраст\n",
    "    \"city\": \"Санкт-Петербург\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    validate(instance=invalid_data, schema=schema)\n",
    "    print(\"Данные валидны\")\n",
    "except ValidationError as e:\n",
    "    print(f\"Ошибка валидации: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 5: Отчёт и анализ проделанной работы\n",
    "Создание итогового отчёта:\n",
    "   - Сгенерируйте отчёт в текстовом файле или в формате JSON с анализом выполнения всех заданий:\n",
    "     - Описание возникших трудностей и способы их решения.\n",
    "     - Время, затраченное на выполнение каждого задания.\n",
    "     - Выводы о проделанной работе и предложенные улучшения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчет сохранен в файл 'task_report.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_report(tasks):\n",
    "    report = {\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"tasks\": tasks,\n",
    "        \"overall_conclusion\": \"Работа выполнена успешно. Предложенные улучшения: автоматизировать процесс валидации данных.\"\n",
    "    }\n",
    "    \n",
    "    # Сохраняем отчет в JSON файл\n",
    "    with open('task_report.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(report, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"Отчет сохранен в файл 'task_report.json'\")\n",
    "\n",
    "# Пример использования\n",
    "tasks = [\n",
    "    {\n",
    "        \"name\": \"Создание JSON Schema\",\n",
    "        \"difficulties\": \"Сложность в определении правильной структуры схемы\",\n",
    "        \"solution\": \"Изучение документации JSON Schema и примеров использования\",\n",
    "        \"time_spent\": \"2 часа\",\n",
    "        \"conclusion\": \"Успешно создана схема для валидации данных о человеке\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Обработка ошибок валидации\",\n",
    "        \"difficulties\": \"Сложность в обработке различных типов ошибок\",\n",
    "        \"solution\": \"Использование try-except блоков и детальный анализ ошибок ValidationError\",\n",
    "        \"time_spent\": \"3 часа\",\n",
    "        \"conclusion\": \"Реализована подробная обработка ошибок с генерацией понятных сообщений\"\n",
    "    }\n",
    "]\n",
    "\n",
    "generate_report(tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
